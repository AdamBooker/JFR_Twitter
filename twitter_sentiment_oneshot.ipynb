{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below demonstrates how to use the OpenAI API to create text embeddings that can be used to classify text without training data, also known as one-shot classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below assumes you have an environment variable named OPENAI_SECRET that is the openAI secret characters of your account. \n",
    "\n",
    "Using the terminal on macos the command to create an environment variable is: export OPENAI_SECRET='enter your secret key between the quotes'\n",
    "\n",
    "On Windows, search for environment variables and create an environment variable named OPENAI_SECRET with your OpenAI secret phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_SECRET\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates an openAI client object that can be used to access the openAI API endpoints.\n",
    "\n",
    "This example used the text-embedding-3-small model, which costs around 10 cents per million tokens.\n",
    "\n",
    "The codebase tiktoken tokenizes text into numbers that correspond to groups of letters in the text-embedding-3-small model input layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_SECRET\"))\n",
    "model = 'text-embedding-3-small'\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below loads a file of newline delimited JSON records. The list variable out will hold records for the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = [json.loads(z) for z in open('in/twtr2015orcl.json')]\n",
    "out = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below calculates cosine similarity. Cosine similarity is defined by the dot product scaled by the cross product of two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below tokenizes classification labels and retireves embeddings for classification cetegories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [encoding.encode(z) for z in ['technical analysis','no financial information','accounting information']]\n",
    "labels_embeddings = [z.embedding for z in client.embeddings.create(input= labels, model = model).data]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below iterates through the dataset 10 records at a time and retrieves embeddings that represent the text of each tweet. It then calculates the cosine distance between classification labels and the text of each tweet and saves the output to the out list variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for x in range(0,len(j)-10,10):\n",
    "    ids = [j[z]['id']['$numberLong'] for z in range(x,x+10)]\n",
    "    texts = [encoding.encode(j[z]['text']) for z in range(x,x+10)]\n",
    "    texts_embeddings = [z.embedding for z in client.embeddings.create(input = texts, model=model).data]\n",
    "    for k1,t in enumerate(texts_embeddings):\n",
    "        o = {ids[k1] : []}\n",
    "        for l in labels_embeddings:\n",
    "            o[ids[k1]].append(cos_sim(l,t))\n",
    "        out.append(o)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below saves the results to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out/twtr2015orcl_oneshot.txt','w') as f:\n",
    "    f.write('id\\ttechnical analysis\\tno financial information\\taccounting information\\n')\n",
    "    for i in out:\n",
    "        for j in i:\n",
    "            f.write(f'{j}\\t{i[j][0]}\\t{i[j][1]}\\t{i[j][2]}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
